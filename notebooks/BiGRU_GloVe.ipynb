{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncSlK3qbo7Iz",
        "outputId": "d9edfb6f-e655-4a4a-8db4-e224c3829f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Setup Complete. Libraries imported and Google Drive mounted.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Mount Google Drive to access your files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Setup Complete. Libraries imported and Google Drive mounted.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the GloVe embeddings file\n",
        "# This is a ~822MB file, so it might take a few minutes depending on Colab's network speed.\n",
        "print(\"Downloading GloVe embeddings...\")\n",
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "print(\"\\nUnzipping the file...\")\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "print(\"\\nDownload and unzipping complete. You should now see 'glove.6B.100d.txt' in your file list.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0b4doKupP2K",
        "outputId": "607ea26c-3393-4563-d864-87a7d883f650"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading GloVe embeddings...\n",
            "--2025-10-04 00:41:00--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-10-04 00:41:00--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2025-10-04 00:43:39 (5.18 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "\n",
            "Unzipping the file...\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "\n",
            "Download and unzipping complete. You should now see 'glove.6B.100d.txt' in your file list.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary to store the word vectors\n",
        "embeddings_index = {}\n",
        "\n",
        "# Path to the GloVe file\n",
        "glove_file_path = 'glove.6B.100d.txt'\n",
        "\n",
        "print(f\"Loading word vectors from {glove_file_path}...\")\n",
        "\n",
        "# Open the file and load the data\n",
        "with open(glove_file_path, encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Loaded {len(embeddings_index)} word vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9yAGbCpriUP",
        "outputId": "c55fd827-0355-4f5e-e4a6-2ed20360fa8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading word vectors from glove.6B.100d.txt...\n",
            "Loaded 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load your dataset\n",
        "# Make sure this path is correct for your Google Drive setup\n",
        "file_path = '/content/drive/MyDrive/Depression detection dataset/BSMDD_main.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Drop any rows with missing text to be safe\n",
        "df.dropna(subset=['text_banglish'], inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 2. Define the same text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()  # Convert to lowercase, ensure it's a string\n",
        "    text = re.sub(r'[^a-z\\s]', '', text) # Remove punctuation, numbers, and special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
        "    return text\n",
        "\n",
        "# 3. Apply the preprocessing function to create a 'cleaned_text' column\n",
        "df['cleaned_text'] = df['text_banglish'].apply(preprocess_text)\n",
        "\n",
        "# 4. Tokenize the cleaned text\n",
        "df['tokenized_text'] = df['cleaned_text'].apply(lambda x: x.split())\n",
        "\n",
        "# Display the first few rows to verify the output\n",
        "print(\"DataFrame after preprocessing and tokenization:\")\n",
        "print(df[['text_banglish', 'cleaned_text', 'tokenized_text', 'label']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6rgN354ri0r",
        "outputId": "bb739715-6303-4e25-ec67-009b76dd87b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame after preprocessing and tokenization:\n",
            "                                       text_banglish  \\\n",
            "0  manasika sharirikabhabe asustha klanta puro ji...   \n",
            "1  daya sathe thakuna atyanta dirgha apanake pada...   \n",
            "2  janatama sathe bhula loka kharapa jibana katiy...   \n",
            "3  anetibha imreji spikarera anusarana biraktikar...   \n",
            "4  anetibha imreji spikarera anusarana biraktikar...   \n",
            "\n",
            "                                        cleaned_text  \\\n",
            "0  manasika sharirikabhabe asustha klanta puro ji...   \n",
            "1  daya sathe thakuna atyanta dirgha apanake pada...   \n",
            "2  janatama sathe bhula loka kharapa jibana katiy...   \n",
            "3  anetibha imreji spikarera anusarana biraktikar...   \n",
            "4  anetibha imreji spikarera anusarana biraktikar...   \n",
            "\n",
            "                                      tokenized_text  label  \n",
            "0  [manasika, sharirikabhabe, asustha, klanta, pu...      1  \n",
            "1  [daya, sathe, thakuna, atyanta, dirgha, apanak...      1  \n",
            "2  [janatama, sathe, bhula, loka, kharapa, jibana...      1  \n",
            "3  [anetibha, imreji, spikarera, anusarana, birak...      1  \n",
            "4  [anetibha, imreji, spikarera, anusarana, birak...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Use Keras Tokenizer to convert texts to integer sequences ---\n",
        "texts = df['cleaned_text'].tolist()\n",
        "labels = df['label'].values\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1 # +1 for the padding token\n",
        "print(f\"Found {len(word_index)} unique tokens in the dataset.\")\n",
        "\n",
        "# --- 2. Pad sequences to a uniform length ---\n",
        "lengths = [len(s) for s in sequences]\n",
        "maxlen = int(np.percentile(lengths, 95))\n",
        "print(f\"Padding sequences to a max length of: {maxlen}\")\n",
        "\n",
        "X = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post')\n",
        "y = labels\n",
        "\n",
        "# --- 3. Create the embedding matrix using GloVe vectors ---\n",
        "embedding_dim = 100 # This must match the dimensionality of the GloVe vectors we loaded\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words found in embedding index will be put into the matrix.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        misses += 1\n",
        "\n",
        "print(f\"\\nEmbedding Matrix Shape: {embedding_matrix.shape}\")\n",
        "print(f\"Converted {hits} words ({misses} misses)\")\n",
        "print(f\"Coverage: {100 * hits / (hits + misses):.2f}% of the vocabulary is covered by GloVe.\")\n",
        "\n",
        "\n",
        "# --- 4. Split data into training and testing sets ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y)\n",
        "\n",
        "print(f\"\\nTraining data shape (X_train): {X_train.shape}\")\n",
        "print(f\"Testing data shape (X_test): {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44Ir-_bNsIN1",
        "outputId": "c64ddc75-3d1f-4dfe-fb9b-7b5cf874c61a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 56826 unique tokens in the dataset.\n",
            "Padding sequences to a max length of: 192\n",
            "\n",
            "Embedding Matrix Shape: (56827, 100)\n",
            "Converted 3578 words (53248 misses)\n",
            "Coverage: 6.30% of the vocabulary is covered by GloVe.\n",
            "\n",
            "Training data shape (X_train): (17528, 192)\n",
            "Testing data shape (X_test): (4382, 192)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Build the BiGRU Model ---\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 1. Embedding Layer\n",
        "# We load our GloVe-based embedding matrix as the weights.\n",
        "# We set trainable=False to keep the GloVe vectors frozen.\n",
        "model.add(Embedding(input_dim=vocab_size,\n",
        "                    output_dim=embedding_dim, # Should be 100\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=maxlen,\n",
        "                    trainable=False))\n",
        "\n",
        "# 2. Bidirectional GRU Layer\n",
        "model.add(Bidirectional(GRU(units=64)))\n",
        "\n",
        "# 3. Dropout for regularization\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# 4. A standard Dense layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# 5. Final Output Layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# --- Compile the Model ---\n",
        "# We use the same settings as the previous model for a fair comparison.\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
        "\n",
        "# --- Print Model Summary ---\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "a34TBmlzsIvc",
        "outputId": "d6a1011e-6659-4e8b-a3ea-213d030fbedc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │     \u001b[38;5;34m5,682,700\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,682,700</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,682,700\u001b[0m (21.68 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,682,700</span> (21.68 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,682,700\u001b[0m (21.68 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,682,700</span> (21.68 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# --- Train the Model ---\n",
        "\n",
        "print(\"Starting model training with GloVe embeddings...\")\n",
        "\n",
        "# Use EarlyStopping to prevent overfitting and save the best model\n",
        "# It will monitor the validation loss and stop if it doesn't improve for 3 epochs.\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Define number of epochs and batch size\n",
        "epochs = 20\n",
        "batch_size = 32\n",
        "\n",
        "# Start the timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Stop the timer\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print the training time\n",
        "training_time = end_time - start_time\n",
        "print(f\"\\nTraining finished in {training_time:.2f} seconds.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmI_BtA6sT_d",
        "outputId": "d07d1b00-9eaa-4a8d-ae95-7080bb1f5997"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model training with GloVe embeddings...\n",
            "Epoch 1/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 235ms/step - accuracy: 0.5955 - loss: 0.6549 - precision: 0.6011 - recall: 0.5470 - val_accuracy: 0.7188 - val_loss: 0.5622 - val_precision: 0.7230 - val_recall: 0.7099\n",
            "Epoch 2/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 233ms/step - accuracy: 0.7196 - loss: 0.5535 - precision: 0.7089 - recall: 0.7371 - val_accuracy: 0.7414 - val_loss: 0.5440 - val_precision: 0.7934 - val_recall: 0.6533\n",
            "Epoch 3/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 238ms/step - accuracy: 0.7561 - loss: 0.5128 - precision: 0.7501 - recall: 0.7658 - val_accuracy: 0.7545 - val_loss: 0.5245 - val_precision: 0.7956 - val_recall: 0.6852\n",
            "Epoch 4/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 233ms/step - accuracy: 0.7706 - loss: 0.4944 - precision: 0.7602 - recall: 0.7897 - val_accuracy: 0.7718 - val_loss: 0.4933 - val_precision: 0.7665 - val_recall: 0.7819\n",
            "Epoch 5/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 231ms/step - accuracy: 0.7846 - loss: 0.4740 - precision: 0.7736 - recall: 0.8088 - val_accuracy: 0.7727 - val_loss: 0.4870 - val_precision: 0.7909 - val_recall: 0.7418\n",
            "Epoch 6/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 234ms/step - accuracy: 0.7984 - loss: 0.4478 - precision: 0.7879 - recall: 0.8191 - val_accuracy: 0.7791 - val_loss: 0.4772 - val_precision: 0.7727 - val_recall: 0.7911\n",
            "Epoch 7/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 238ms/step - accuracy: 0.8112 - loss: 0.4273 - precision: 0.7980 - recall: 0.8293 - val_accuracy: 0.7901 - val_loss: 0.4635 - val_precision: 0.7723 - val_recall: 0.8230\n",
            "Epoch 8/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 230ms/step - accuracy: 0.8250 - loss: 0.3980 - precision: 0.8224 - recall: 0.8314 - val_accuracy: 0.7713 - val_loss: 0.4882 - val_precision: 0.7654 - val_recall: 0.7828\n",
            "Epoch 9/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 234ms/step - accuracy: 0.8247 - loss: 0.3879 - precision: 0.8157 - recall: 0.8445 - val_accuracy: 0.7971 - val_loss: 0.4533 - val_precision: 0.8224 - val_recall: 0.7582\n",
            "Epoch 10/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 238ms/step - accuracy: 0.8474 - loss: 0.3562 - precision: 0.8377 - recall: 0.8552 - val_accuracy: 0.8069 - val_loss: 0.4383 - val_precision: 0.7774 - val_recall: 0.8604\n",
            "Epoch 11/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 237ms/step - accuracy: 0.8586 - loss: 0.3338 - precision: 0.8512 - recall: 0.8694 - val_accuracy: 0.8003 - val_loss: 0.4485 - val_precision: 0.7674 - val_recall: 0.8622\n",
            "Epoch 12/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 229ms/step - accuracy: 0.8677 - loss: 0.3150 - precision: 0.8593 - recall: 0.8754 - val_accuracy: 0.8094 - val_loss: 0.4461 - val_precision: 0.8232 - val_recall: 0.7883\n",
            "Epoch 13/20\n",
            "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 234ms/step - accuracy: 0.8769 - loss: 0.2919 - precision: 0.8695 - recall: 0.8840 - val_accuracy: 0.8083 - val_loss: 0.4583 - val_precision: 0.8269 - val_recall: 0.7801\n",
            "\n",
            "Training finished in 1740.48 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Performance Evaluation on Test Set ---\n",
        "print(\"--- Final Performance Evaluation (GloVe Model) ---\")\n",
        "\n",
        "# Get model predictions (probabilities are needed for ROC-AUC)\n",
        "y_pred_probs = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to binary class labels (0 or 1) for other metrics\n",
        "y_pred = (y_pred_probs > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calculate and print the metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_probs) # ROC-AUC is calculated on the prediction probabilities\n",
        "\n",
        "print(f\"\\nOverall Test Metrics:\")\n",
        "print(f\"Accuracy:      {accuracy:.4f}\")\n",
        "print(f\"Precision:     {precision:.4f}\")\n",
        "print(f\"Recall:        {recall:.4f}\")\n",
        "print(f\"F1 Score:      {f1:.4f}\")\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\\n\")\n",
        "\n",
        "# Print a detailed classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Not Depressed (0)', 'Depressed (1)']))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "\n",
        "# --- 2. Practical Time Complexity Analysis ---\n",
        "print(\"--- Time Complexity (GloVe Model) ---\")\n",
        "\n",
        "# We already have the training time\n",
        "print(f\"Total Training Time: {training_time:.2f} seconds (approx. {training_time/60:.1f} minutes)\")\n",
        "\n",
        "# Measure Inference Time\n",
        "inference_start_time = time.time()\n",
        "_ = model.predict(X_test)\n",
        "inference_end_time = time.time()\n",
        "\n",
        "total_inference_time = inference_end_time - inference_start_time\n",
        "avg_inference_time_per_sample = total_inference_time / len(X_test)\n",
        "\n",
        "print(f\"Total Inference Time for {len(X_test)} samples: {total_inference_time:.4f} seconds\")\n",
        "print(f\"Average Inference Time per Sample: {avg_inference_time_per_sample * 1000:.4f} milliseconds\\n\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "\n",
        "# --- 3. Practical Space Complexity Analysis ---\n",
        "print(\"--- Space Complexity (GloVe Model) ---\")\n",
        "\n",
        "# Number of trainable parameters\n",
        "total_params = model.count_params()\n",
        "print(f\"Total Model Parameters: {total_params:,}\")\n",
        "\n",
        "# Model size on disk (using a new name to avoid overwriting the Word2Vec model)\n",
        "model_filename = \"depression_detection_bigru_glove.keras\"\n",
        "model.save(model_filename)\n",
        "model_size_bytes = os.path.getsize(model_filename)\n",
        "model_size_mb = model_size_bytes / (1024 * 1024)\n",
        "\n",
        "print(f\"Model Size on Disk: {model_size_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbAItAwnsdpf",
        "outputId": "678b3f58-a1d2-4a62-a633-108eef51aefc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Final Performance Evaluation (GloVe Model) ---\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step\n",
            "\n",
            "Overall Test Metrics:\n",
            "Accuracy:      0.8069\n",
            "Precision:     0.7774\n",
            "Recall:        0.8604\n",
            "F1 Score:      0.8168\n",
            "ROC-AUC Score: 0.8879\n",
            "\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Not Depressed (0)       0.84      0.75      0.80      2190\n",
            "    Depressed (1)       0.78      0.86      0.82      2192\n",
            "\n",
            "         accuracy                           0.81      4382\n",
            "        macro avg       0.81      0.81      0.81      4382\n",
            "     weighted avg       0.81      0.81      0.81      4382\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1650  540]\n",
            " [ 306 1886]]\n",
            "\n",
            "==================================================\n",
            "\n",
            "--- Time Complexity (GloVe Model) ---\n",
            "Total Training Time: 1740.48 seconds (approx. 29.0 minutes)\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step\n",
            "Total Inference Time for 4382 samples: 6.5849 seconds\n",
            "Average Inference Time per Sample: 1.5027 milliseconds\n",
            "\n",
            "==================================================\n",
            "\n",
            "--- Space Complexity (GloVe Model) ---\n",
            "Total Model Parameters: 5,750,605\n",
            "Model Size on Disk: 22.50 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The model is already trained, so let's print its summary again.\n",
        "# This will now show the complete, built version of the model.\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "WuRg00orzzBc",
        "outputId": "9c4f98a0-96f3-490c-df21-10a698b48376"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m5,682,700\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m63,744\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,682,700</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">63,744</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,886,417\u001b[0m (22.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,886,417</span> (22.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,905\u001b[0m (265.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,905</span> (265.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,682,700\u001b[0m (21.68 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,682,700</span> (21.68 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m135,812\u001b[0m (530.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,812</span> (530.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the tokenizer object used for the GloVe model\n",
        "with open('tokenizer_glove.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print(\"Tokenizer for GloVe model saved to 'tokenizer_glove.pickle'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxvUzdW70RQK",
        "outputId": "cc88359e-40e5-4202-a717-dd5d6755f1b8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer for GloVe model saved to 'tokenizer_glove.pickle'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ahPdg4Ig0nD0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}